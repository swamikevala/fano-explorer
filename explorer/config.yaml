# Fano Explorer Configuration

# Browser settings
browser:
  # Path to Chrome executable (leave empty for auto-detect)
  chrome_path: ""
  # Whether to run headless (invisible) - set to false for debugging
  headless: false
  # Directory to store browser sessions
  user_data_dir: "./browser_data"
  # Slow down operations for stability (milliseconds)
  slow_mo: 100
  # Viewport size (smaller to avoid window cutoff on Windows)
  viewport_width: 1280
  viewport_height: 720

# Model endpoints
models:
  chatgpt:
    url: "https://chat.openai.com"
    # Selectors for detecting states (CSS selectors)
    selectors:
      input: "textarea[data-id='root']"
      send: "button[data-testid='send-button']"
      response: "div[data-message-author-role='assistant']"
      rate_limit_patterns:
        - "You've reached the limit"
        - "Usage cap reached"
        - "try again later"
    # How long to wait for response (seconds) - Pro mode can be slow
    response_timeout: 3600
    
  gemini:
    url: "https://gemini.google.com"
    selectors:
      input: "rich-textarea"
      send: "button.send-button"
      response: "message-content"
      deep_think_toggle: "button[aria-label='Deep Think']"
      rate_limit_patterns:
        - "unavailable"
        - "try again tomorrow"
        - "quota"
      # Deep Think overload - temporary, can retry after waiting
      deep_think_overload_patterns:
        - "A lot of people are using Deep Think"
        - "need a moment to sort through"
    response_timeout: 3600  # Deep Think can be slow
    # Retry settings for Deep Think overload
    deep_think_retry:
      enabled: true
      wait_seconds: 600  # 10 minutes default
      max_retries: 3

  claude:
    url: "https://claude.ai/new"
    selectors:
      input:
        - "div.ProseMirror[contenteditable='true']"
        - "div[contenteditable='true']"
      send:
        - "button[aria-label='Send message']"
        - "button[data-testid='send-button']"
        - "fieldset button:not([disabled])"
      response:
        - "[data-testid='message-content']"
        - "div[data-is-streaming]"
        - ".font-claude-message"
      extended_thinking_toggle:
        - "[data-testid='extended-thinking-toggle']"
        - "button[aria-label*='thinking']"
      rate_limit_patterns:
        - "rate limit"
        - "too many messages"
        - "try again later"
        - "usage limit"
    response_timeout: 3600  # Extended Thinking can take a while
    # Extended Thinking settings
    extended_thinking:
      initial_wait: 30
      stability_checks: 15

# Model selection weights (higher = more likely to be chosen)
# Gemini tends to explore creatively, ChatGPT tends to critique rigorously
model_weights:
  exploration:
    gemini: 60
    chatgpt: 40
  critique:
    gemini: 30
    chatgpt: 70
  synthesis:
    gemini: 50
    chatgpt: 50

# Deep/Pro mode daily limits (preserved for synthesis and breakthroughs)
# Note: Claude Extended Thinking is lighter than ChatGPT Pro or Gemini Deep Think,
# so it can be used more liberally (effectively as default mode)
deep_modes:
  gemini_deep_think:
    daily_limit: 20
  chatgpt_pro:
    daily_limit: 100
  claude_extended_thinking:
    daily_limit: 500  # High limit - can use as default

# Exploration seed prompt
exploration:
  # Introduction describing what we're exploring
  intro: |
    You are exploring deep mathematical connections between:
    - Fano plane incidence geometry (7 points, 7 lines, 3 points per line) and its related mathematical structures/geometries
    - The Yogic energy system of chakras and nadis and the 5 elements
    - Sanskrit grammar (particularly Panini's system, 14 Maheshvara Sutras)
    - The Sriyantra or srichakra
    - Indian classical music theory (12 swaras, 22 shrutis, ragas, 72 melakartas)
    - Yogic/Tantric cosmology and practice systems:
      • Tantric texts (Vijñāna Bhairava's 112 dharanas, Tantraloka)
      • Yogic texts (Yoga Sutras, Hatha Yoga Pradipika, 84 asanas)
      • Samkhya/Vedantic philosophy (24/25 tattvas, 36 tattvas in Kashmir Shaivism)
      • Puranic cosmology (7 lokas, 14 lokas, yuga cycles)
    - Modern physics: String theory, Quantum mechanics, Alternate explanation of Gravity

  # Key numbers to decode
  key_numbers: "3, 5, 7, 14, 16, 21, 22, 24, 36, 72, 84, 108, 112, 114"

  # Goals for the exploration
  goals: |
    Your goal is to find mathematical structures that:
    1. Feel NATURAL and INEVITABLE (not forced)
    2. Are ELEGANT, INTERESTING, and BEAUTIFUL
    3. DECODE WHY these specific numbers appear across traditions

  # Guidance for exploration style
  guidance: |
    Follow your mathematical curiosity. Let the structure reveal itself.
    If something feels forced, abandon it. If something feels inevitable,
    pursue it—even if it seems unrelated to anything practical.

    The criterion for a good direction is: does this feel DISCOVERED
    rather than INVENTED? Does it explain WHY the numbers are what they are,
    not just THAT they match?

# Orchestration settings
orchestration:
  # Seconds between exploration cycles
  poll_interval: 30
  # Seconds to wait when all models rate-limited
  backoff_base: 300  # 5 minutes
  backoff_max: 3600  # 1 hour max
  # How many exchange rounds before considering chunk-ready
  min_exchanges_for_chunk: 4
  # Maximum exchanges before forcing synthesis
  max_exchanges_per_thread: 12
  # Number of concurrent exploration threads
  max_active_threads: 3

# Chunk synthesis settings
synthesis:
  # Minimum critique rounds before chunk is ready
  min_critiques: 2
  # Keywords that suggest profundity (boost chunk-readiness)
  profundity_signals:
    - "this explains"
    - "naturally follows"
    - "must be"
    - "inevitable"
    - "elegant"
    - "beautiful"
    - "symmetric"
  # Keywords that suggest problems (delay chunk-readiness)  
  doubt_signals:
    - "but wait"
    - "doesn't quite"
    - "forcing"
    - "arbitrary"
    - "why would"
    - "seems ad hoc"

# Review server settings
review_server:
  host: "127.0.0.1"
  port: 8765
  # Enable debug mode for auto-reload on file changes (templates, Python files)
  debug: true

# Atomic chunking settings
chunking:
  # "atomic" extracts multiple insights per thread, "monolithic" is old behavior
  mode: "atomic"
  # Filter out insights below this confidence: "high", "medium", or "low"
  min_confidence_to_keep: "low"
  # Maximum insights to extract per thread (per LLM in panel mode)
  max_insights_per_thread: 15
  # Maximum final insights after consolidation
  max_final_insights: 10

  # Panel-based extraction (recommended): all 3 LLMs propose independently, then consolidate
  # This captures cross-domain bridges that a single conservative LLM might miss
  use_panel_extraction: true

# Dependency resolution settings
dependencies:
  # Keyword overlap threshold for matching deps to blessed chunks
  semantic_match_threshold: 0.5
  # Maximum blessed insights to include in extraction prompt
  max_blessed_in_prompt: 20
  # Flag during review if insight has unresolved dependencies
  warn_on_unresolved: true

# Deduplication settings
# NOTE: Main deduplication config is now centralized in fano/config.yaml
# These settings are kept for backward compatibility but the shared module
# will load from the root config.yaml by default.
deduplication:
  # Enable deduplication checking
  enabled: true

# Mathematical verification settings (DeepSeek Prover V2 via OpenRouter)
math_verification:
  # Enable DeepSeek math verification (runs between Round 1 and Round 2)
  enabled: true
  # Environment variable containing OpenRouter API key
  openrouter_api_key_env: "OPENROUTER_API_KEY"
  # OpenRouter API endpoint
  endpoint: "https://openrouter.ai/api/v1"
  # Model to use for verification (OpenRouter model path)
  model: "deepseek/deepseek-prover-v2"
  # Automatically reject insights with mathematically refuted claims
  auto_reject_refuted: true
  # Minimum confidence (0.0-1.0) to auto-reject refuted claims
  auto_reject_confidence_threshold: 0.8
  # Tags that always trigger math verification
  required_tags:
    - proof
    - theorem
    - lemma
    - corollary
    - formula
    - equation
    - derivation
    - group
    - isomorphism
    - automorphism

# Automated review panel settings
review_panel:
  # Enable automated LLM review panel
  enabled: true
  # Environment variable containing Claude API key
  claude_api_key_env: "ANTHROPIC_API_KEY"
  # Claude model to use (Opus for extraction/refinement, best at precise articulation)
  claude_model: "claude-opus-4-20250514"

  # Round 1: Independent review (standard modes)
  round1:
    use_deep_modes: false

  # Refinement settings (Claude Opus rewrites based on critiques)
  refinement:
    # Maximum refinement attempts before escalating to deliberation
    max_refinement_rounds: 2
    # If true, escalate to deliberation after failed refinement
    escalate_after_failed_refinement: true

  # Round 2: Deep analysis (deep think modes)
  round2:
    use_deep_modes: true

  # Round 3: Structured deliberation
  round3:
    enabled: true
    max_exchanges: 3

  # Outcome handling
  outcomes:
    unanimous_bless: "auto_bless"
    unanimous_reject: "auto_reject"
    unanimous_uncertain: "needs_development"
    disputed_majority_bless: "bless_with_flag"
    disputed_majority_reject: "reject_with_flag"

# Chunk augmentation settings
augmentation:
  # Enable augmentation of blessed insights
  enabled: true
  # Automatically generate augmentations for all blessed chunks
  auto_generate: true
  # Must pass verification before attaching
  require_verification: true

  # Type-specific settings
  types:
    diagram:
      enabled: true
      format: "svg"  # or "png"
      tool: "matplotlib"  # or "graphviz"
    table:
      enabled: true
      format: "markdown"
    proof:
      enabled: true
      require_review: true  # Second LLM must verify
    code:
      enabled: true
      execute: true  # Actually run the code
      timeout_seconds: 30

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  file: "./logs/exploration.log"
  max_bytes: 10485760  # 10MB
  backup_count: 5
