# Fano Platform Configuration
# Unified configuration for all components

# =============================================================================
# LLM BACKENDS
# =============================================================================
llm:
  # Pool service settings (for browser-based backends)
  pool:
    host: "127.0.0.1"
    port: 9000
    auto_start: true  # Start pool automatically with fano.py

  # Consensus settings for documenter
  consensus:
    use_deep_mode: false  # Disable pro/deep modes (they're slow)

  # Backend configuration
  backends:
    gemini:
      enabled: true
      type: "browser"  # Requires pool service
      browser_data_dir: "./browser_data/gemini"
      url: "https://gemini.google.com/app"
      response_timeout_seconds: 3600
      deep_mode:
        name: "Deep Think"
        daily_limit: 20
        reset_hour: 0

    chatgpt:
      enabled: true
      type: "browser"  # Requires pool service
      browser_data_dir: "./browser_data/chatgpt"
      url: "https://chatgpt.com"
      response_timeout_seconds: 3600
      deep_mode:
        name: "Pro Mode"
        daily_limit: 100
        reset_hour: 0

    claude:
      enabled: true
      type: "browser"  # Uses playwright browser automation via pool
      browser_data_dir: "./browser_data/claude"
      url: "https://claude.ai"
      response_timeout_seconds: 3600
      deep_mode:
        name: "Extended Thinking"
        daily_limit: 100
        reset_hour: 0

    openrouter:
      enabled: true
      type: "api"
      api_key_env: "OPENROUTER_API_KEY"
      default_model: "deepseek/deepseek-r1"

  # Browser settings (for browser-based backends)
  browser:
    headless: false  # Set true for production/server
    viewport_width: 1280
    viewport_height: 720
    slow_mo: 100

# =============================================================================
# CONSENSUS SETTINGS
# =============================================================================
consensus:
  # Which backends to use for consensus (order matters for tie-breaking)
  backends:
    - gemini
    - chatgpt
    - claude

  # Default settings
  max_rounds: 3
  require_unanimous: false  # If false, 2/3 majority is enough

  # When to use deep modes
  deep_modes:
    # Explorer uses deep modes for Round 2 review
    explorer_review_round2: true
    # Documenter uses deep modes occasionally for section review
    documenter_section_review: true
    # Math evaluation - use deep modes for thorough analysis
    documenter_math_evaluation: false

# =============================================================================
# CONTROL PANEL
# =============================================================================
control:
  host: "127.0.0.1"
  port: 8080
  debug: true

# =============================================================================
# SERVICE DEPENDENCIES AND LIFECYCLE
# =============================================================================
services:
  pool:
    auto_start: true              # Start pool when control server starts
    health_timeout_seconds: 30    # Max wait for healthy on startup
  explorer:
    depends_on: [pool]
  documenter:
    depends_on: [pool]
  researcher:
    depends_on: [pool]

# =============================================================================
# EXPLORER SETTINGS
# =============================================================================
explorer:
  # Imported from explorer/config.yaml - key settings only
  orchestration:
    poll_interval: 30
    max_active_threads: 3
    min_exchanges_for_chunk: 4
    max_exchanges_per_thread: 12

  review_panel:
    enabled: true
    round1:
      use_deep_modes: false
    round2:
      use_deep_modes: true
    round3:
      enabled: true
      max_exchanges: 3

# =============================================================================
# DOCUMENTER SETTINGS
# =============================================================================
documenter:
  document:
    path: "document/main.md"
    archive_dir: "document/archive"
    snapshot_time: "00:00"

  inputs:
    blessed_insights_dir: "explorer/data/chunks/insights/blessed/"
    # Optional free-form guidance file for document direction
    guidance_file: "document/guidance.md"

  work_allocation:
    new_material: 70
    review_existing: 30

  review:
    max_age_days: 7
    use_deep_mode: true  # Use deep modes when reviewing sections

  context:
    max_tokens: 8000

  termination:
    max_consecutive_disputes: 3
    max_consensus_calls_per_session: 100

  # Math evaluation criteria (can be adjusted)
  evaluation:
    # How strict to be - "strict" requires profound/inevitable, "moderate" is more permissive
    strictness: "moderate"

# =============================================================================
# DEDUPLICATION SETTINGS (shared across explorer and documenter)
# =============================================================================
deduplication:
  # Enable deduplication checking
  enabled: true

  # LLM model for semantic duplicate detection (use cheap/fast model)
  model: "claude-sonnet-4-20250514"

  # Detection method: LLM-first approach (recommended for mathematical content)
  # Heuristics often miss semantic duplicates where same concept is expressed differently
  use_signature_check: true   # Instant - catches exact duplicates
  use_heuristic_check: false  # Disabled by default - LLM is better for math
  use_llm_check: true         # Primary detection method
  use_batch_llm: true         # Efficient batch checking

  # Batch size for LLM checks (items checked in one API call)
  batch_size: 20

  # Heuristic thresholds (only used if use_heuristic_check is true)
  keyword_threshold: 0.40
  concept_threshold: 0.45
  combined_threshold: 0.50

  # LLM confidence requirements
  require_high_confidence: false

  # Timeout for LLM calls (seconds)
  llm_timeout: 60

  # Stats logging interval (log stats every N checks, 0 to disable)
  stats_log_interval: 50

# =============================================================================
# LOGGING
# =============================================================================
logging:
  level: "INFO"
  directory: "./logs"
  format: "jsonl"  # JSON Lines for machine parsing
